from typing import List, Dict, Any
from app.infrastructure.external.openai_client import OpenAIClient
from app.infrastructure.db.vector.vector_db import get_vector_db
from app.infrastructure.embedding.embedding_model import get_embedding_model
from app.common.logging.logging_config import get_logger

logger = get_logger(__name__)


class ChatService:
    """ì‚¬ìš©ì ì±„íŒ… ì„œë¹„ìŠ¤ (RAG í¬í•¨)"""

    def __init__(self, openai_client: OpenAIClient = None,
                 vector_db=None, embedding_model=None):
        # ì˜ì¡´ì„± ì£¼ì… ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        self.openai_client = openai_client or OpenAIClient()
        self.vector_db = vector_db or get_vector_db()
        self.embedding_model = embedding_model or get_embedding_model()

        self.default_system_prompt = """ë„ˆëŠ” ì´ˆë“±í•™ìƒ ëŒë´„ì„ ìƒë‹˜ì´ì•¼. 
    ì£¼ì–´ì§„ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì¤˜.
    ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ë˜, 
    ì°¸ê³  ìë£Œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•´ì¤˜."""

    async def chat_with_rag(self, prompt: str, collection_name: str = None, top_k: int = 3) -> str:
        """
        ì‚¬ìš©ì ì±„íŒ… - RAG ì‹œìŠ¤í…œ ìë™ ì‹¤í–‰

        Args:
            prompt: ì‚¬ìš©ì ì§ˆë¬¸
            collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ëª… (Noneì´ë©´ ëª¨ë“  ì»¬ë ‰ì…˜)
            top_k: ì°¸ì¡°í•  ë¬¸ì„œ ìˆ˜

        Returns:
            GPT ì‘ë‹µ
        """
        try:
            logger.info(f"ğŸ” RAG ì±„íŒ… ì‹œì‘: '{prompt}' (top_k={top_k}, collection={collection_name or 'all'})")
            
            # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            relevant_docs = await self.search_relevant_documents(prompt, collection_name, top_k)
            logger.info(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(relevant_docs)}ê°œ")

            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self.build_context_from_documents(relevant_docs)
            logger.info(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)}ì")

            # 3. GPT ì‘ë‹µ ìƒì„±
            response = await self.generate_response_with_context(prompt, context)
            logger.info(f" GPT ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response)}ì")

            return response

        except Exception as e:
            logger.error(f"âŒ RAG ì±„íŒ… ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def search_relevant_documents(self, query: str, collection_name: str = None, top_k: int = 3, 
                                      similarity_threshold: float = 0.6) -> List[Dict[str, Any]]:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            logger.debug(f"ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘: '{query}' (top_k={top_k}, ì„ê³„ê°’={similarity_threshold})")
            
            query_embedding = await self.embedding_model.get_embedding(query)
            logger.debug(f" ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(query_embedding)}ì°¨ì›")
            
            results = []

            # ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ê²°ì •
            if collection_name:
                collections = [collection_name]
            else:
                collections = ["korean_word_problems", "card_check"]

            logger.debug(f"ğŸ“‚ ê²€ìƒ‰í•  ì»¬ë ‰ì…˜: {collections}")

            # ê° ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
            for coll_name in collections:
                collection = self.vector_db.get_collection(coll_name)
                if collection:
                    logger.debug(f"ğŸ” {coll_name} ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ì¤‘...")
                    
                    search_results = collection.query(
                        query_embeddings=[query_embedding],
                        n_results=top_k * 2  # ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í•„í„°ë§
                    )

                    for i in range(len(search_results['documents'][0])):
                        similarity = 1 - search_results['distances'][0][i]
                        
                        # ìœ ì‚¬ë„ ì„ê³„ê°’ ì´ìƒì¸ ë¬¸ì„œë§Œ í¬í•¨
                        if similarity >= similarity_threshold:
                            results.append({
                                'document': search_results['documents'][0][i],
                                'metadata': search_results['metadatas'][0][i],
                                'distance': search_results['distances'][0][i],
                                'collection': coll_name
                            })
                    
                    logger.debug(f"âœ… {coll_name}ì—ì„œ {len(search_results['documents'][0])}ê°œ ë¬¸ì„œ ë°œê²¬, {len([r for r in results if r['collection'] == coll_name])}ê°œ í•„í„°ë§ë¨")
                else:
                    logger.warning(f"âš ï¸ {coll_name} ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x['distance'])
            final_results = results[:top_k]
            
            logger.info(f"ğŸ“š ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(final_results)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’: {similarity_threshold})")
            for i, doc in enumerate(final_results):
                similarity = round(1 - doc['distance'], 4)
                logger.info(f"   {i+1}. [{doc['collection']}] ìœ ì‚¬ë„: {similarity} - {doc['document'][:100]}...")

            return final_results

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []


    async def generate_response_with_context(self, prompt: str, context: str) -> str:
        """ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ GPT ì‘ë‹µ ìƒì„±"""
        try:
            logger.debug(f" GPT ì‘ë‹µ ìƒì„± ì‹œì‘ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)}ì)")
            
            response = await self.openai_client.generate_response_with_context(
                prompt=prompt,
                context=context,
                system_prompt=self.default_system_prompt
            )
            
            logger.debug(f"âœ… GPT ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response)}ì")
            return response
            
        except Exception as e:
            logger.error(f"âŒ GPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


    def build_context_from_documents(self, documents: List[Dict[str, Any]]) -> str:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not documents:
            logger.warning("âš ï¸ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ì–´ì„œ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©")
            return "ì°¸ê³  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."

        context_parts = []
        for i, doc in enumerate(documents, 1):
            similarity = round(1 - doc.get('distance', 0), 4)
            content = doc.get('document', doc.get('text', ''))
            collection = doc.get('collection', 'unknown')
            
            # ì»¬ë ‰ì…˜ë³„ë¡œ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
            if collection == "card_check":
                context_parts.append(f"{i}. [ì¹´ë“œ] ìœ ì‚¬ë„: {similarity} - {content}")
            elif collection == "korean_word_problems":
                context_parts.append(f"{i}. [ë¬¸ì œ] ìœ ì‚¬ë„: {similarity} - {content}")
            else:
                context_parts.append(f"{i}. [ê¸°íƒ€] ìœ ì‚¬ë„: {similarity} - {content}")

        context = "\n".join(context_parts)
        logger.debug(f" ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ, {len(context)}ì")
        
        return context


    async def simple_chat(self, prompt: str) -> str:
        """
        RAG ì—†ì´ ê°„ë‹¨í•œ ì±„íŒ… (í…ŒìŠ¤íŠ¸ìš©)

        Args:
            prompt: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            GPT ì‘ë‹µ
        """
        try:
            logger.info(f"ğŸ’¬ ê°„ë‹¨ ì±„íŒ…: '{prompt}'")
            
            messages = [
                {"role": "system", "content": self.default_system_prompt},
                {"role": "user", "content": prompt}
            ]
            response = await self.openai_client.chat_completion(messages)
            
            logger.info(f"âœ… ê°„ë‹¨ ì±„íŒ… ì™„ë£Œ: {len(response)}ì")
            return response
            
        except Exception as e:
            logger.error(f"âŒ ê°„ë‹¨ ì±„íŒ… ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def get_chat_service() -> ChatService:
    """Chat ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return ChatService()