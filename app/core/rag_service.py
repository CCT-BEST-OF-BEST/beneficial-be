from typing import List, Dict, Any, Optional
from app.core.vector_db import get_vector_db
from app.core.embedding_model import get_embedding_model
from app.core.data_loader.korean_word_problems_loader import get_korean_word_problems
from app.core.data_loader.card_check_loader import get_card_check_data
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

class RAGService:
    def __init__(self):
        """RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.vector_db = get_vector_db()
        self.embedding_model = get_embedding_model()
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    async def initialize(self):
        # ë°ì´í„°ê°€ ë²¡í„° DBì— ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¸ë±ì‹±
        await self._ensure_data_indexed()

    async def async_init(self):
        # ë°ì´í„°ê°€ ë²¡í„° DBì— ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¸ë±ì‹±
        await self._ensure_data_indexed()
        """RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.vector_db = get_vector_db()
        self.embedding_model = get_embedding_model()
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    async def _ensure_data_indexed(self):
        """ë°ì´í„°ê°€ ë²¡í„° DBì— ì¸ë±ì‹±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìë™ ì¸ë±ì‹±"""
        try:
            # ê° ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œ ìˆ˜ í™•ì¸
            korean_collection = self.vector_db.get_collection("korean_word_problems")
            card_collection = self.vector_db.get_collection("card_check")

            korean_count = korean_collection.count() if korean_collection else 0
            card_count = card_collection.count() if card_collection else 0

            print(f"ğŸ” í˜„ì¬ ì¸ë±ì‹±ëœ ë¬¸ì„œ: korean_word_problems={korean_count}, card_check={card_count}")

            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìë™ ì¸ë±ì‹±
            if korean_count == 0:
                print("ğŸ” í•œêµ­ì–´ ë‹¨ì–´ ë¬¸ì œ ë°ì´í„° ìë™ ì¸ë±ì‹± ì¤‘...")
                await self._index_korean_word_problems()

            if card_count == 0:
                print("ğŸ” ì¹´ë“œ ì²´í¬ ë°ì´í„° ìë™ ì¸ë±ì‹± ì¤‘...")
                await self._index_card_check_data()

        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ì¸ë±ì‹± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _index_korean_word_problems(self):
        """í•œêµ­ì–´ ë‹¨ì–´ ë¬¸ì œ ë°ì´í„°ë¥¼ ë²¡í„° DBì— ì¸ë±ì‹±"""
        try:
            data = get_korean_word_problems()
            if not data:
                return

            documents = self.embedding_model.prepare_documents_for_indexing(data, "korean_word_problems")

            texts = [doc["text"] for doc in documents]
            ids = [doc["id"] for doc in documents]
            metadatas = [doc["metadata"] for doc in documents]

            embeddings = await self.embedding_model.get_embeddings(texts)

            collection = self.vector_db.get_collection("korean_word_problems")
            collection.add(
                embeddings=embeddings,
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )
            print(f"âœ… í•œêµ­ì–´ ë‹¨ì–´ ë¬¸ì œ {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ í•œêµ­ì–´ ë‹¨ì–´ ë¬¸ì œ ì¸ë±ì‹± ì‹¤íŒ¨: {e}")

    async def _index_card_check_data(self):
        """ì¹´ë“œ ì²´í¬ ë°ì´í„°ë¥¼ ë²¡í„° DBì— ì¸ë±ì‹±"""
        try:
            data = get_card_check_data()
            if not data:
                return

            documents = self.embedding_model.prepare_documents_for_indexing(data, "card_check")

            texts = [doc["text"] for doc in documents]
            ids = [doc["id"] for doc in documents]
            metadatas = [doc["metadata"] for doc in documents]

            embeddings = await self.embedding_model.get_embeddings(texts)

            collection = self.vector_db.get_collection("card_check")
            collection.add(
                embeddings=embeddings,
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )
            print(f"âœ… ì¹´ë“œ ì²´í¬ {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ ì¹´ë“œ ì²´í¬ ì¸ë±ì‹± ì‹¤íŒ¨: {e}")

    async def search_relevant_documents(self, query: str, collection_name: str = None, top_k: int = 3) -> List[
        Dict[str, Any]]:
        """
        ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰í•  ì§ˆë¬¸
            collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ëª… (Noneì´ë©´ ëª¨ë“  ì»¬ë ‰ì…˜)
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

        Returns:
            ê´€ë ¨ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì§ˆë¬¸ì„ ì„ë² ë”©
            query_embedding = await self.embedding_model.get_embedding(query)

            results = []

            if collection_name:
                # íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œë§Œ ê²€ìƒ‰
                collection = self.vector_db.get_collection(collection_name)
                if collection:
                    search_results = collection.query(
                        query_embeddings=[query_embedding],
                        n_results=top_k
                    )

                    for i in range(len(search_results['documents'][0])):
                        results.append({
                            'document': search_results['documents'][0][i],
                            'metadata': search_results['metadatas'][0][i],
                            'distance': search_results['distances'][0][i],
                            'collection': collection_name
                        })
            else:
                # ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
                collections = ["korean_word_problems", "card_check"]

                for coll_name in collections:
                    collection = self.vector_db.get_collection(coll_name)
                    if collection:
                        search_results = collection.query(
                            query_embeddings=[query_embedding],
                            n_results=top_k
                        )

                        for i in range(len(search_results['documents'][0])):
                            results.append({
                                'document': search_results['documents'][0][i],
                                'metadata': search_results['metadatas'][0][i],
                                'distance': search_results['distances'][0][i],
                                'collection': coll_name
                            })

            # ê±°ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ê¹Œìš¸ìˆ˜ë¡ ê´€ë ¨ì„± ë†’ìŒ)
            results.sort(key=lambda x: x['distance'])

            return results[:top_k]

        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def chat_with_rag(self, prompt: str, collection_name: str = None, top_k: int = 3) -> str:
        """
        RAGë¥¼ ì‚¬ìš©í•˜ì—¬ GPTì™€ ëŒ€í™”í•©ë‹ˆë‹¤.

        Args:
            prompt: ì‚¬ìš©ì ì§ˆë¬¸
            collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ëª…
            top_k: ì°¸ì¡°í•  ë¬¸ì„œ ìˆ˜

        Returns:
            GPT ì‘ë‹µ
        """
        try:
            # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            relevant_docs = await self.search_relevant_documents(prompt, collection_name, top_k)

            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(relevant_docs)

            # 3. GPTì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
            system_message = """ë„ˆëŠ” ì´ˆë“±í•™ìƒ ëŒë´„ì„ ìƒë‹˜ì´ì•¼. 
ì£¼ì–´ì§„ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì¤˜.
ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ë˜, 
ì°¸ê³  ìë£Œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•´ì¤˜."""

            user_message = f"""ì°¸ê³  ìë£Œ:
{context}

ì§ˆë¬¸: {prompt}"""

            # 4. GPT í˜¸ì¶œ
            response = await self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=500,
                temperature=0.7
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"âŒ RAG ì±„íŒ… ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _build_context(self, relevant_docs: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤."""
        if not relevant_docs:
            return "ì°¸ê³  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."

        context_parts = []
        for i, doc in enumerate(relevant_docs, 1):
            context_parts.append(f"{i}. {doc['document']}")

        return "\n".join(context_parts)


# ì „ì—­ RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service = None


async def get_rag_service():
    """ì „ì—­ RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë°˜í™˜í•˜ê³  ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global rag_service
    if rag_service is None:
        rag_service = RAGService()
        await rag_service.initialize()
    return rag_service